{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. Data Loading and Preparation\n",
    "# ----------------------------\n",
    "\n",
    "# Load the training dataset\n",
    "df = pd.read_csv('ais_train.csv', sep='|')\n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('ais_test.csv', sep=',')\n",
    "\n",
    "# Ensure data is sorted by time\n",
    "df = df.sort_values(by='time').reset_index(drop=True)\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "df['time'] = pd.to_datetime(df['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 2. Feature Engineering\n",
    "# ----------------------------\n",
    "\n",
    "# Encode vesselId\n",
    "label_encoder = LabelEncoder()\n",
    "df['vesselId_encoded'] = label_encoder.fit_transform(df['vesselId'])\n",
    "\n",
    "# Define lag features\n",
    "lag_features_latitude = [1, 2]\n",
    "lag_features_longitude = [1]\n",
    "\n",
    "# Create lagged features, delta features, and cyclical transformations\n",
    "for lag in lag_features_latitude:\n",
    "    # Lagged features\n",
    "    df[f'latitude_t-{lag}'] = df.groupby('vesselId')['latitude'].shift(lag)\n",
    "    df[f'sog_t-{lag}'] = df.groupby('vesselId')['sog'].shift(lag)\n",
    "    df[f'cog_t-{lag}'] = df.groupby('vesselId')['cog'].shift(lag)\n",
    "    df[f'heading_t-{lag}'] = df.groupby('vesselId')['heading'].shift(lag)\n",
    "    \n",
    "    # Delta features\n",
    "    df[f'delta_latitude_t-{lag}'] = df['latitude'] - df[f'latitude_t-{lag}']\n",
    "    df[f'delta_sog_t-{lag}'] = df['sog'] - df[f'sog_t-{lag}']\n",
    "    df[f'delta_cog_t-{lag}'] = df['cog'] - df[f'cog_t-{lag}']\n",
    "    df[f'delta_heading_t-{lag}'] = df['heading'] - df[f'heading_t-{lag}']\n",
    "    \n",
    "    # Cyclical transformations for 'cog' and 'heading'\n",
    "    df[f'cog_t-{lag}_sin'] = np.sin(np.radians(df[f'cog_t-{lag}']))\n",
    "    df[f'cog_t-{lag}_cos'] = np.cos(np.radians(df[f'cog_t-{lag}']))\n",
    "    df[f'heading_t-{lag}_sin'] = np.sin(np.radians(df[f'heading_t-{lag}']))\n",
    "    df[f'heading_t-{lag}_cos'] = np.cos(np.radians(df[f'heading_t-{lag}']))\n",
    "\n",
    "# Create lagged features and delta features for longitude\n",
    "for lag in lag_features_longitude:\n",
    "    df[f'longitude_t-{lag}'] = df.groupby('vesselId')['longitude'].shift(lag)\n",
    "    df[f'delta_longitude_t-{lag}'] = df['longitude'] - df[f'longitude_t-{lag}']\n",
    "\n",
    "# Create rolling averages and their cyclical transformations\n",
    "df['sog_rolling_avg'] = df.groupby('vesselId')['sog'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "df['cog_rolling_avg'] = df.groupby('vesselId')['cog'].transform(lambda x: x.rolling(window=3, min_periods=1).mean())\n",
    "df['cog_rolling_avg_sin'] = np.sin(np.radians(df['cog_rolling_avg']))\n",
    "df['cog_rolling_avg_cos'] = np.cos(np.radians(df['cog_rolling_avg']))\n",
    "\n",
    "# Extract time-based features and apply cyclical transformations\n",
    "df['hour'] = df['time'].dt.hour\n",
    "df['day_of_week'] = df['time'].dt.dayofweek\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "\n",
    "# Drop rows with NaN values resulting from lagging\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 3. Define Features and Targets\n",
    "# ----------------------------\n",
    "\n",
    "features = (\n",
    "    [f'latitude_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'longitude_t-{lag}' for lag in lag_features_longitude] +\n",
    "    [f'sog_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'heading_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'delta_latitude_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'delta_longitude_t-{lag}' for lag in lag_features_longitude] +\n",
    "    [f'delta_sog_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'delta_heading_t-{lag}' for lag in lag_features_latitude] +\n",
    "    [f'cog_t-{lag}_sin' for lag in lag_features_latitude] +\n",
    "    [f'cog_t-{lag}_cos' for lag in lag_features_latitude] +\n",
    "    [f'heading_t-{lag}_sin' for lag in lag_features_latitude] +\n",
    "    [f'heading_t-{lag}_cos' for lag in lag_features_latitude] +\n",
    "    ['sog_rolling_avg', 'cog_rolling_avg_sin', 'cog_rolling_avg_cos',\n",
    "     'hour_sin', 'hour_cos', 'day_of_week_sin', 'day_of_week_cos',\n",
    "     'vesselId_encoded']\n",
    ")\n",
    "\n",
    "# Prepare feature matrix X and target vectors y\n",
    "X = df[features]\n",
    "y_latitude = df['latitude']\n",
    "y_longitude = df['longitude']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 4. Prepare for Stacking Ensemble\n",
    "# ----------------------------\n",
    "\n",
    "# Split data into training and validation sets using time-based split\n",
    "split_index = int(len(df) * 0.8)\n",
    "\n",
    "X_train = X.iloc[:split_index]\n",
    "X_val = X.iloc[split_index:]\n",
    "\n",
    "y_lat_train = y_latitude.iloc[:split_index]\n",
    "y_lat_val = y_latitude.iloc[split_index:]\n",
    "\n",
    "y_lon_train = y_longitude.iloc[:split_index]\n",
    "y_lon_val = y_longitude.iloc[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 5. Train Base Models\n",
    "# ----------------------------\n",
    "\n",
    "# Define base models\n",
    "base_models_lat = [\n",
    "    ('xgb', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('rf', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('lgb', lgb.LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "base_models_lon = [\n",
    "    ('xgb', xgb.XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('rf', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        random_state=42\n",
    "    )),\n",
    "    ('lgb', lgb.LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42\n",
    "    ))\n",
    "]\n",
    "\n",
    "# Train base models for latitude\n",
    "for name, model in base_models_lat:\n",
    "    model.fit(X_train, y_lat_train)\n",
    "\n",
    "# Train base models for longitude\n",
    "for name, model in base_models_lon:\n",
    "    model.fit(X_train, y_lon_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 6. Generate Base Model Predictions for Meta-Model Training\n",
    "# ----------------------------\n",
    "\n",
    "# Create new feature set for meta-model (predictions of base models)\n",
    "meta_X_lat_train = pd.DataFrame()\n",
    "meta_X_lat_val = pd.DataFrame()\n",
    "\n",
    "meta_X_lon_train = pd.DataFrame()\n",
    "meta_X_lon_val = pd.DataFrame()\n",
    "\n",
    "# Generate predictions for training and validation sets\n",
    "for name, model in base_models_lat:\n",
    "    meta_X_lat_train[name] = model.predict(X_train)\n",
    "    meta_X_lat_val[name] = model.predict(X_val)\n",
    "\n",
    "for name, model in base_models_lon:\n",
    "    meta_X_lon_train[name] = model.predict(X_train)\n",
    "    meta_X_lon_val[name] = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 7. Train Meta-Model\n",
    "# ----------------------------\n",
    "\n",
    "# Use Linear Regression as meta-model for simplicity\n",
    "meta_model_lat = LinearRegression()\n",
    "meta_model_lon = LinearRegression()\n",
    "\n",
    "# Train meta-models\n",
    "meta_model_lat.fit(meta_X_lat_train, y_lat_train)\n",
    "meta_model_lon.fit(meta_X_lon_train, y_lon_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 8. Evaluate Ensemble Model\n",
    "# ----------------------------\n",
    "\n",
    "# Predict on validation set using meta-model\n",
    "ensemble_lat_pred = meta_model_lat.predict(meta_X_lat_val)\n",
    "ensemble_lon_pred = meta_model_lon.predict(meta_X_lon_val)\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "ensemble_lat_mae = mean_absolute_error(y_lat_val, ensemble_lat_pred)\n",
    "ensemble_lon_mae = mean_absolute_error(y_lon_val, ensemble_lon_pred)\n",
    "\n",
    "print(f\"Ensemble Mean Absolute Error for Latitude: {ensemble_lat_mae}\")\n",
    "print(f\"Ensemble Mean Absolute Error for Longitude: {ensemble_lon_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 9. Prepare Test Data\n",
    "# ----------------------------\n",
    "\n",
    "# [Same preprocessing steps as training data]\n",
    "\n",
    "# Ensure test data is sorted by time\n",
    "test_df = test_df.sort_values(by='time').reset_index(drop=True)\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "test_df['time'] = pd.to_datetime(test_df['time'])\n",
    "\n",
    "# Encode vesselId in test data using the same label encoder\n",
    "test_df['vesselId_encoded'] = test_df['vesselId'].apply(map_vesselId)\n",
    "\n",
    "# Merge the last known data from the training set with the test set\n",
    "latest_known_data = df.groupby('vesselId').last().reset_index()\n",
    "\n",
    "# Merge test data with latest known data\n",
    "test_df = test_df.merge(\n",
    "    latest_known_data[['vesselId', 'latitude', 'longitude', 'sog', 'cog', 'heading']],\n",
    "    on='vesselId',\n",
    "    how='left',\n",
    "    suffixes=('', '_lag1')\n",
    ")\n",
    "\n",
    "# Create lagged features for the test set\n",
    "# For lag=1\n",
    "test_df[f'latitude_t-1'] = test_df['latitude']\n",
    "test_df[f'sog_t-1'] = test_df['sog']\n",
    "test_df[f'cog_t-1'] = test_df['cog']\n",
    "test_df[f'heading_t-1'] = test_df['heading']\n",
    "test_df[f'longitude_t-1'] = test_df['longitude']\n",
    "\n",
    "# For lag=2, use lag=1 data as we don't have further history\n",
    "for lag in [2]:\n",
    "    test_df[f'latitude_t-{lag}'] = test_df[f'latitude_t-1']\n",
    "    test_df[f'sog_t-{lag}'] = test_df[f'sog_t-1']\n",
    "    test_df[f'cog_t-{lag}'] = test_df[f'cog_t-1']\n",
    "    test_df[f'heading_t-{lag}'] = test_df[f'heading_t-1']\n",
    "\n",
    "# Create delta features and cyclical transformations in the test set\n",
    "for lag in lag_features_latitude:\n",
    "    test_df[f'delta_latitude_t-{lag}'] = 0  # Assume no change\n",
    "    test_df[f'delta_sog_t-{lag}'] = 0\n",
    "    test_df[f'delta_cog_t-{lag}'] = 0\n",
    "    test_df[f'delta_heading_t-{lag}'] = 0\n",
    "    \n",
    "    # Cyclical transformations\n",
    "    test_df[f'cog_t-{lag}_sin'] = np.sin(np.radians(test_df[f'cog_t-{lag}']))\n",
    "    test_df[f'cog_t-{lag}_cos'] = np.cos(np.radians(test_df[f'cog_t-{lag}']))\n",
    "    test_df[f'heading_t-{lag}_sin'] = np.sin(np.radians(test_df[f'heading_t-{lag}']))\n",
    "    test_df[f'heading_t-{lag}_cos'] = np.cos(np.radians(test_df[f'heading_t-{lag}']))\n",
    "\n",
    "# For longitude delta features\n",
    "for lag in lag_features_longitude:\n",
    "    test_df[f'delta_longitude_t-{lag}'] = 0  # Assume no change\n",
    "\n",
    "# Rolling averages for the test set\n",
    "test_df['sog_rolling_avg'] = test_df['sog']\n",
    "test_df['cog_rolling_avg'] = test_df['cog']\n",
    "test_df['cog_rolling_avg_sin'] = np.sin(np.radians(test_df['cog_rolling_avg']))\n",
    "test_df['cog_rolling_avg_cos'] = np.cos(np.radians(test_df['cog_rolling_avg']))\n",
    "\n",
    "# Time-based features and cyclical transformations\n",
    "test_df['hour'] = test_df['time'].dt.hour\n",
    "test_df['day_of_week'] = test_df['time'].dt.dayofweek\n",
    "test_df['hour_sin'] = np.sin(2 * np.pi * test_df['hour'] / 24)\n",
    "test_df['hour_cos'] = np.cos(2 * np.pi * test_df['hour'] / 24)\n",
    "test_df['day_of_week_sin'] = np.sin(2 * np.pi * test_df['day_of_week'] / 7)\n",
    "test_df['day_of_week_cos'] = np.cos(2 * np.pi * test_df['day_of_week'] / 7)\n",
    "\n",
    "# Fill any remaining missing values with zeros\n",
    "test_df.fillna(0, inplace=True)\n",
    "\n",
    "# Prepare features for test set\n",
    "X_test = test_df[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 10. Generate Base Model Predictions on Test Set\n",
    "# ----------------------------\n",
    "\n",
    "meta_X_lat_test = pd.DataFrame()\n",
    "meta_X_lon_test = pd.DataFrame()\n",
    "\n",
    "for name, model in base_models_lat:\n",
    "    meta_X_lat_test[name] = model.predict(X_test)\n",
    "\n",
    "for name, model in base_models_lon:\n",
    "    meta_X_lon_test[name] = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 11. Make Final Predictions with Meta-Model\n",
    "# ----------------------------\n",
    "\n",
    "# Predict latitude and longitude\n",
    "ensemble_lat_pred_test = meta_model_lat.predict(meta_X_lat_test)\n",
    "ensemble_lon_pred_test = meta_model_lon.predict(meta_X_lon_test)\n",
    "\n",
    "# Ensure predicted coordinates are within valid ranges\n",
    "test_df['latitude_predicted'] = ensemble_lat_pred_test.clip(-90, 90)\n",
    "test_df['longitude_predicted'] = ((ensemble_lon_pred_test + 180) % 360) - 180\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 12. Prepare Submission File\n",
    "# ----------------------------\n",
    "\n",
    "# Create the output DataFrame\n",
    "output_df = test_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "output_df.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
