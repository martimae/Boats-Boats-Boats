{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv('new_train.csv', parse_dates=['time'])\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('ais_test.csv', parse_dates=['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the training data\n",
    "train_df = train_df.sort_values(by=['vesselId', 'time'])\n",
    "\n",
    "# Get the last known data point for each vessel\n",
    "last_known_positions = train_df.groupby('vesselId').last().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge test data with last known positions\n",
    "merged_df = test_df.merge(\n",
    "    last_known_positions,\n",
    "    on='vesselId',\n",
    "    suffixes=('_test', '_train'),\n",
    "    how='left'  # Use 'left' join to keep all test data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify vessels with missing training data\n",
    "missing_vessels = merged_df[merged_df['time_train'].isnull()]['vesselId'].unique()\n",
    "\n",
    "if len(missing_vessels) > 0:\n",
    "    print(\"Warning: The following vesselIds are in the test set but not in the training set:\")\n",
    "    print(missing_vessels)\n",
    "    \n",
    "    # Option 1: Remove these vessels from the merged_df\n",
    "    # merged_df = merged_df[~merged_df['vesselId'].isin(missing_vessels)]\n",
    "    \n",
    "    # Option 2: Handle them separately (e.g., assign default values)\n",
    "    # For this example, we'll assign default latitude and longitude of 0.0\n",
    "    merged_df['latitude'] = merged_df['latitude'].fillna(0.0)\n",
    "    merged_df['longitude'] = merged_df['longitude'].fillna(0.0)\n",
    "    merged_df['sog'] = merged_df['sog'].fillna(0.0)\n",
    "    merged_df['cog'] = merged_df['cog'].fillna(0.0)\n",
    "    merged_df['time_train'] = merged_df['time_train'].fillna(merged_df['time_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a threshold for movement\n",
    "MOVEMENT_THRESHOLD = 0.5  # knots\n",
    "\n",
    "def is_moving(sog):\n",
    "    return sog > MOVEMENT_THRESHOLD\n",
    "\n",
    "# Apply the function to create a new column\n",
    "merged_df['is_moving'] = merged_df['sog'].apply(is_moving)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference in hours\n",
    "merged_df['time_diff_hours'] = (merged_df['time_test'] - merged_df['time_train']).dt.total_seconds() / 3600.0\n",
    "\n",
    "# For any negative or zero time differences, set to zero\n",
    "merged_df['time_diff_hours'] = merged_df['time_diff_hours'].apply(lambda x: max(x, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install geopy if not already installed\n",
    "# !pip install geopy\n",
    "\n",
    "from geopy import distance\n",
    "from geopy.point import Point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_position(row):\n",
    "    if row['is_moving']:\n",
    "        try:\n",
    "            # Get last known position\n",
    "            lat1 = row['latitude']\n",
    "            lon1 = row['longitude']\n",
    "            \n",
    "            # Get course over ground (degrees) (prøver på heading)\n",
    "            cog = row['heading']\n",
    "            \n",
    "            # Get speed over ground (knots), convert to km/h\n",
    "            sog_knots = row['sog']\n",
    "            sog_kmh = sog_knots * 1.852  # 1 knot = 1.852 km/h\n",
    "            \n",
    "            # Get time difference in hours\n",
    "            time_diff = row['time_diff_hours']\n",
    "            \n",
    "            # Calculate distance traveled in kilometers\n",
    "            distance_traveled = sog_kmh * time_diff\n",
    "            \n",
    "            # Create a geopy Point for the last known position\n",
    "            origin = Point(lat1, lon1)\n",
    "            \n",
    "            # Calculate destination point given distance and bearing\n",
    "            # geopy uses bearing in degrees\n",
    "            destination = distance.distance(kilometers=distance_traveled).destination(origin, bearing=cog)\n",
    "            \n",
    "            # Get predicted latitude and longitude\n",
    "            new_lat = destination.latitude\n",
    "            new_lon = destination.longitude\n",
    "            \n",
    "            # Ensure latitude is within -90 to 90 degrees\n",
    "            new_lat = max(min(new_lat, 90), -90)\n",
    "            \n",
    "            # Ensure longitude is within -180 to 180 degrees\n",
    "            new_lon = (new_lon + 180) % 360 - 180\n",
    "            \n",
    "            return pd.Series({'latitude_predicted': new_lat, 'longitude_predicted': new_lon})\n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting position for vesselId {row['vesselId']}: {e}\")\n",
    "            # In case of error, return last known position\n",
    "            return pd.Series({'latitude_predicted': row['latitude'], 'longitude_predicted': row['longitude']})\n",
    "    else:\n",
    "        # For stationary vessels, return last known position\n",
    "        return pd.Series({'latitude_predicted': row['latitude'], 'longitude_predicted': row['longitude']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row\n",
    "merged_df[['latitude_predicted', 'longitude_predicted']] = merged_df.apply(predict_position, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the final output dataframe\n",
    "output_df = merged_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Ensure the columns are in the correct order\n",
    "output_df = output_df[['ID', 'longitude_predicted', 'latitude_predicted']]\n",
    "\n",
    "# Save to CSV\n",
    "output_df.to_csv('baseline_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
